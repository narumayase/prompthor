# anyompt - API de integraciÃ³n con LLMs

Este proyecto provee una API que integra mÃºltiples modelos de lenguaje grandes (LLM).

## CaracterÃ­sticas

- Enviar prompts a OpenAI o Groq desde un mismo endpoint.
- Cambiar dinÃ¡micamente el modelo utilizado sin modificar el cÃ³digo cliente.
- Escalar y extender a otros LLMs en el futuro.
- IntegraciÃ³n orientada a eventos con Kafka: Opcional, envÃ­a las respuestas a un tÃ³pico de Kafka para su posterior procesamiento.

Por el momento estÃ¡ integrada con OpenAI y con Groq, este Ãºltimo permite mÃºltiples modelos gratuitos con cierto lÃ­mite de token, ver documentaciÃ³n en: [Groq](https://console.groq.com/docs/overview)

### Prerequisitos

- Go 1.21 o mayor
- API key de OpenAI (opcional, para integraciÃ³n con OpenAI)
- API key de Groq (opcional, para integraciÃ³n con Groq)
- Kafka (opcional, para integraciÃ³n con Kafka)

## ğŸš€ InstalaciÃ³n

1. Instalar dependencias:

```bash
go mod tidy
```

2. Configurar las variables de entorno:

```bash
cp env.example .env
# Editar .env con los valores descriptos debajo.
```

3. Ejecutar la aplicaciÃ³n:

```bash
go run main.go
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

Crear un archivo `.env` basado en `env.example`:

- `CHAT_MODEL`: Modelo de chat a usar. Si se selecciona "OpenAI", se usa la API de OpenAI; de lo contrario, se usa Groq.
    - Ejemplo para Groq: llama-3.3-70b-versatile
    - Por defecto: openai/gpt-oss-20b
- `OPENAI_API_KEY`: API key de OpenAI (requerida para OpenAI)
- `GROQ_API_KEY`: API key de Groq (requerida para Groq)
- `GROQ_URL`: URL de la API de Groq (por defecto: https://api.groq.com/openai/v1/responses)
- `PORT`: Puerto del servidor (por defecto: 8080)
- `LOG_LEVEL`: Nivel de log (debug, info, warn, error, fatal, panic - por defecto: info)
- `KAFKA_ENABLED`: Habilita la integraciÃ³n con Kafka (true o false)
- `KAFKA_BROKERS`: Lista de brokers de Kafka separados por comas
- `KAFKA_TOPIC`: TÃ³pico de Kafka para enviar eventos

### ConfiguraciÃ³n de OpenAI API

1. **Obtener acceso a la API de OpenAI:**
  - Crear una cuenta en OpenAI
  - Crear un Token de API

### ConfiguraciÃ³n de Groq API

1. **Obtener acceso a la API de Groq:**
   - Crear una cuenta en Groq
   - Crear un Token de API

## ğŸ“¡ Endpoints

### POST /api/v1/chat/ask

EnvÃ­a un prompt al LLM elegido y recibe una respuesta.

**Request:**
```json
{
  "prompt": "Â¿CuÃ¡l es la capital de Francia?"
}
```

**Response:**
```json
{
  "response": "La capital de Francia es ParÃ­s."
}
```

### GET /health

Verifica el estado de la API.

**Response:**
```json
{
  "status": "OK",
  "message": "anyompt API is running"
}
```

#### Usando curl:

```bash
# Health check
curl http://localhost:8080/health

# Chat endpoint
curl -X POST http://localhost:8080/api/v1/chat/ask \
  -H "Content-Type: application/json" \
  -d '{"prompt": "CuÃ¡l es la capital de Francia?"}'
```

## ğŸ—ï¸ Arquitectura

Este proyecto sigue los principios de Clean Architecture:

- **Domain**: Entidades, interfaces de repositorio y casos de uso
- **Application**: ImplementaciÃ³n de casos de uso
- **Infrastructure**: Implementaciones de repositorios de OpenAI y Groq
- **Interfaces**: Controladores HTTP y routers

## ğŸ“ Estructura del Proyecto

```
anyompt/
â”œâ”€â”€ cmd/                  # Puntos de entrada de la aplicaciÃ³n
â”‚   â””â”€â”€ server/           # Servidor principal
â”œâ”€â”€ internal/             # CÃ³digo especÃ­fico del proyecto
â”‚   â”œâ”€â”€ config/           # ConfiguraciÃ³n
â”‚   â”œâ”€â”€ infrastructure/   # Implementaciones de repositorios
â”‚   â””â”€â”€ interfaces/       # Controladores HTTP
â”‚       â”œâ”€â”€ http/         # Controlador handler
â”‚       â””â”€â”€ middleware/   # Middlewares
â”œâ”€â”€ pkg/                  # CÃ³digo reutilizable y pÃºblico
â”‚   â”œâ”€â”€ domain/           # Entidades e interfaces del dominio
â”‚   â””â”€â”€ application/      # Casos de uso
â”œâ”€â”€ main.go               # Punto de entrada principal
â”œâ”€â”€ go.mod                # Dependencias de Go
â”œâ”€â”€ README_ES.md          # Este archivo
â””â”€â”€ README.md             # README en inglÃ©s
```

## ğŸ§ª Pruebas

### Ejecutar Pruebas

Para ejecutar todas las pruebas:

```bash
go test ./...
```

Para ejecutar pruebas con salida detallada:

```bash
go test -v ./...
```

Para ejecutar pruebas de un paquete especÃ­fico:

```bash
go test ./internal/config/
go test ./cmd/server/
```

### Cobertura de Pruebas

Para verificar la cobertura de pruebas (excluyendo mocks):

```bash
# Generar reporte de cobertura
go test -coverprofile=coverage.out ./...

# Ver reporte de cobertura en terminal
go tool cover -func=coverage.out

# Generar reporte HTML de cobertura
go tool cover -html=coverage.out -o coverage.html

# Ver cobertura excluyendo mocks
go test -coverprofile=coverage.out ./... && \
go tool cover -func=coverage.out | grep -v "mocks"
```

### Ejecutar Benchmarks

```bash
go test -bench=. ./...
```

## BackLog

- [x] Pruebas unitarias
- [ ] Agregar otros LLMs de pago
- [ ] Pruebas de integraciÃ³n
- [ ] DocumentaciÃ³n de API con Swagger

